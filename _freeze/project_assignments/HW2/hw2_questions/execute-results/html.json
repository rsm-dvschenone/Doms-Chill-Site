{
  "hash": "b63b9559054e88396d65fde8437ddca5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Poisson Regression Examples\"\nauthor: \"Dominic Schenone\"\ndate: \"May 11, 2025\"\ncallout-appearance: minimal # this hides the blue \"i\" icon on .callout-notes\nexecute:\n  echo: false\n  warning: false\n  message: false\n---\n\n\n## Blueprinty Case Study\n\n### Introduction\n\nBlueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty's software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty's software and after using it. Unfortunately, such data is not available. \n\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm's number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty's software. The marketing team would like to use this data to make the claim that firms using Blueprinty's software are more successful in getting their patent applications approved.\n\n\n### Data\n\n\n\n\n\n::: {#d2b6799f .cell execution_count=3}\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   patents     1500 non-null   int64  \n 1   region      1500 non-null   object \n 2   age         1500 non-null   float64\n 3   iscustomer  1500 non-null   int64  \n 4   age_std     1500 non-null   float64\n 5   age_sq_std  1500 non-null   float64\ndtypes: float64(3), int64(2), object(1)\nmemory usage: 70.4+ KB\n```\n:::\n:::\n\n\n::: {#cb8d10d9 .cell execution_count=4}\n\n::: {.cell-output .cell-output-stdout}\n```\nMean number of patents by customer status:\n iscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](hw2_questions_files/figure-html/cell-5-output-2.png){width=597 height=449}\n:::\n:::\n\n\n::: {.callout-note title=\"Histogram Interpretation\"}\nWe observe that customers tend to have a higher number of patents on average, and their distribution is right-skewed compared to non-customers. This justifies including `iscustomer` as a predictor in our Poisson regression model.\n:::\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\n::: {#e1e7f609 .cell execution_count=5}\n\n::: {.cell-output .cell-output-stdout}\n```\nAge summary by customer status:\n              count       mean       std   min   25%   50%    75%   max\niscustomer                                                            \n0           1019.0  26.101570  6.945426   9.0  21.0  25.5  31.25  47.5\n1            481.0  26.900208  7.814678  10.0  20.5  26.5  32.50  49.0\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](hw2_questions_files/figure-html/cell-6-output-2.png){width=597 height=449}\n:::\n:::\n\n\n::: {.callout-note title=\"Age Distribution Interpretation\"}\n\nThe **age distribution** reveals that customers (orange) tend to skew slightly older than non-customers (blue).  \nWhile both groups peak around the mid- to late-20s, customers show a **broader spread into their 30s and 40s**,  \nsuggesting that older individuals may be more likely to become customers. \n:::\n\n::: {#e8980e5a .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](hw2_questions_files/figure-html/cell-7-output-1.png){width=589 height=507}\n:::\n:::\n\n\n::: {.callout-note title=\"Regionality Distribution Interpretation\"}\nRegionally, the **Northeast stands out**: it has the **lowest proportion of customers**,  \nwith more than half of individuals in that region being non-customers.  \nIn contrast, the **Midwest, Northwest, South, and Southwest** all show a strong majority of customers.  \nThis geographic pattern implies that regional targeting or market presence might be influencing customer conversion.\n\n:::\n\n### Estimation of Simple Poisson Model\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\nLet \\( Y_1, Y_2, \\dots, Y_n \\overset{\\text{iid}}{\\sim} \\text{Poisson}(\\lambda) \\). The probability mass function is:\n\n\\[\nf(Y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\n\nThen the likelihood function for a sample of size \\( n \\) is:\n\n\\[\n\\mathcal{L}(\\lambda \\mid Y_1, \\dots, Y_n) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n\\]\n\nTaking the natural logarithm to get the log-likelihood:\n\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log Y_i! \\right)\n\\]\n\nThis is the log-likelihood expression we will use to estimate \\( \\lambda \\) in our simple Poisson model.\n\n\n\n::: {#e463c329 .cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![](hw2_questions_files/figure-html/cell-9-output-1.png){width=621 height=449}\n:::\n:::\n\n\n::: {.callout-note title=\"Log-Likelihood Curve Interpretation\"}\n\nThe log-likelihood curve reaches a clear peak, suggesting the maximum likelihood estimate (MLE) of \\( \\lambda \\) lies around that peak.  \nThis visual check helps confirm the function is well-behaved and the model is appropriate for estimating a central rate parameter from count data.\n\n:::\n\nWe start with the log-likelihood for \\( n \\) i.i.d. observations from a Poisson distribution:\n\n\\[\n\\ell(\\lambda) = \\sum_{i=1}^{n} \\left( -\\lambda + Y_i \\log \\lambda - \\log Y_i! \\right)\n\\]\n\nTo find the MLE of \\( \\lambda \\), we take the first derivative with respect to \\( \\lambda \\):\n\n\\[\n\\frac{d\\ell}{d\\lambda} = \\sum_{i=1}^{n} \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n= -n + \\frac{1}{\\lambda} \\sum_{i=1}^{n} Y_i\n\\]\n\nSet the derivative equal to zero and solve for \\( \\lambda \\):\n\n\\[\n-n + \\frac{1}{\\lambda} \\sum_{i=1}^{n} Y_i = 0\n\\Rightarrow \\frac{1}{\\lambda} \\sum_{i=1}^{n} Y_i = n\n\\Rightarrow \\lambda = \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\bar{Y}\n\\]\n\nThus, the MLE of \\( \\lambda \\) is simply the **sample mean** \\( \\bar{Y} \\).  \nThis makes intuitive sense, since the Poisson distribution has both its mean and variance equal to \\( \\lambda \\).\n\n::: {#1afebb42 .cell execution_count=9}\n\n::: {.cell-output .cell-output-stdout}\n```\nMLE of lambda (numerical optimization): 3.6847\nSample mean of Y: 3.6847\n```\n:::\n:::\n\n\n::: {.callout-note title=\"Results from Optimization\"}\n\nUsing numerical optimization, the estimated MLE of \\( \\lambda \\) is approximately **{lambda_mle:.4f}**,  \nwhich aligns closely with the sample mean \\( \\bar{Y} = {sample_mean:.4f} \\).  \nThis matches our earlier mathematical derivation, confirming that the Poisson MLE for \\( \\lambda \\) is the mean of the observed data.\n\n:::\n\n\n\n### Estimation of Poisson Regression Model\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that $Y_i = \\text{Poisson}(\\lambda_i)$ where $\\lambda_i = \\exp(X_i'\\beta)$. The interpretation is that the success rate of patent awards is not constant across all firms ($\\lambda$) but rather is a function of firm characteristics $X_i$. Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n::: {.callout-note title=\"Updated Log-Likelihood Function\"}\n\n\n\n:::\n\n\n_todo: Use your function along with R's optim() or Python's sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1's to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors._\n\n::: {.callout-note title=\"Build the Design Matrix X\"}\n\n\n\n:::\n\n::: {.callout-note title=\"Estimate ùõΩ\"}\n\n::: {#24021945 .cell execution_count=12}\n\n::: {.cell-output .cell-output-stdout}\n```\n         Current function value: 3258.072145\n         Iterations: 18\n         Function evaluations: 252\n         Gradient evaluations: 28\n```\n:::\n:::\n\n\n::: {.callout-note title=\"Extracting Coefficients\"}\n\n::: {#4ca113f1 .cell execution_count=13}\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variable</th>\n      <th>Coefficient</th>\n      <th>Std. Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>intercept</td>\n      <td>1.3447</td>\n      <td>0.0344</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>age_std</td>\n      <td>-0.0577</td>\n      <td>0.0149</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>age_sq_std</td>\n      <td>-0.1558</td>\n      <td>0.0172</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>iscustomer</td>\n      <td>0.2076</td>\n      <td>0.0314</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Northeast</td>\n      <td>0.0292</td>\n      <td>0.0382</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Northwest</td>\n      <td>-0.0176</td>\n      <td>0.0231</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>South</td>\n      <td>0.0566</td>\n      <td>0.0452</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Southwest</td>\n      <td>0.0506</td>\n      <td>0.0417</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.callout-note title=\"Analysis of Coefficients\"}\n\nThe coefficients represent the estimated effect of each variable on the **log expected patent count**.\n\n- Being a customer of Blueprinty is associated with a significant increase in patent counts (Œ≤ = 0.208, SE = 0.031).\n- Age has a small negative effect, and the negative age-squared term suggests a **concave relationship** ‚Äî i.e., patenting peaks in mid-career.\n- Regional effects are relatively minor, with South and Southwest showing small positive deviations.\n\n:::\n\n::: {#6d8bbf6c .cell execution_count=14}\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Tue, 06 Jan 2026   Deviance:                       2143.3\nTime:                        21:15:39   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.3447      0.038     35.059      0.000       1.270       1.420\nx1            -0.0577      0.015     -3.843      0.000      -0.087      -0.028\nx2            -0.1558      0.014    -11.513      0.000      -0.182      -0.129\nx3             0.2076      0.031      6.719      0.000       0.147       0.268\nx4             0.0292      0.044      0.669      0.504      -0.056       0.115\nx5            -0.0176      0.054     -0.327      0.744      -0.123       0.088\nx6             0.0566      0.053      1.074      0.283      -0.047       0.160\nx7             0.0506      0.047      1.072      0.284      -0.042       0.143\n==============================================================================\n```\n:::\n:::\n\n\n::: {.callout-note title=\"Model Validation with statsmodels\"}\n\nTo confirm the accuracy of our custom maximum likelihood estimation (MLE), we refit the same Poisson regression using Python's built-in `statsmodels.GLM()` function.  \n\nThe resulting coefficients and standard errors were nearly identical to our hand-coded implementation, validating both the numerical optimization and our understanding of Poisson regression mechanics.\n\n:::\n\n::: {#8d36e5a8 .cell execution_count=15}\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage increase in predicted patents from being a customer: 0.7928\n```\n:::\n:::\n\n\n::: {.callout-note title=\"Final Analysis\"}\n\nTo assess the effect of Blueprinty's software on patent success, we simulated expected patent counts for all firms under two scenarios:  \none where no firms were customers, and another where all firms were.\n\nThe analysis reveals that, on average, being a Blueprinty customer increases expected patent output by approximately **0.79 patents per firm**.  \n\nThis suggests a **meaningful positive effect** of the software on innovation activity.\n\n:::\n\n\n\n\n## AirBnB Case Study\n\n### Introduction\n\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City.  The data include the following variables:\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n    - `id` = unique ID number for each unit\n    - `last_scraped` = date when information scraped\n    - `host_since` = date when host first listed the unit on Airbnb\n    - `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n    - `room_type` = Entire home/apt., Private room, or Shared room\n    - `bathrooms` = number of bathrooms\n    - `bedrooms` = number of bedrooms\n    - `price` = price per night (dollars)\n    - `number_of_reviews` = number of reviews for the unit on Airbnb\n    - `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n    - `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n    - `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n    - `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n::::\n\n::: {#957ac25f .cell execution_count=16}\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>days</th>\n      <th>last_scraped</th>\n      <th>host_since</th>\n      <th>room_type</th>\n      <th>bathrooms</th>\n      <th>bedrooms</th>\n      <th>price</th>\n      <th>number_of_reviews</th>\n      <th>review_scores_cleanliness</th>\n      <th>review_scores_location</th>\n      <th>review_scores_value</th>\n      <th>instant_bookable</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2515</td>\n      <td>3130</td>\n      <td>4/2/2017</td>\n      <td>9/6/2008</td>\n      <td>Private room</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>59</td>\n      <td>150</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2595</td>\n      <td>3127</td>\n      <td>4/2/2017</td>\n      <td>9/9/2008</td>\n      <td>Entire home/apt</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>230</td>\n      <td>20</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3647</td>\n      <td>3050</td>\n      <td>4/2/2017</td>\n      <td>11/25/2008</td>\n      <td>Private room</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>3831</td>\n      <td>3038</td>\n      <td>4/2/2017</td>\n      <td>12/7/2008</td>\n      <td>Entire home/apt</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>89</td>\n      <td>116</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>4611</td>\n      <td>3012</td>\n      <td>4/2/2017</td>\n      <td>1/2/2009</td>\n      <td>Private room</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>39</td>\n      <td>93</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>t</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#79a169ba .cell execution_count=17}\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\nUnnamed: 0                       0\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n```\n:::\n:::\n\n\n::: {.callout-note title=\"Feature Engineering and Design Matrix\"}\n\n\n\n:::\n::: {.callout-note title=\"Implementing the Poission Regression\"}\n\n::: {#d042a7a2 .cell execution_count=19}\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                30160\nModel:                            GLM   Df Residuals:                    30149\nModel Family:                 Poisson   Df Model:                           10\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -5.2418e+05\nDate:                Tue, 06 Jan 2026   Deviance:                   9.2689e+05\nTime:                        21:15:40   Pearson chi2:                 1.37e+06\nNo. Iterations:                    10   Pseudo R-squ. (CS):             0.6840\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          3.5533      0.016    219.754      0.000       3.522       3.585\nx1            -0.1177      0.004    -31.394      0.000      -0.125      -0.110\nx2             0.0741      0.002     37.197      0.000       0.070       0.078\nx3             0.1131      0.001     75.611      0.000       0.110       0.116\nx4            -0.0769      0.002    -47.796      0.000      -0.080      -0.074\nx5            -0.0911      0.002    -50.490      0.000      -0.095      -0.088\nx6             0.3459      0.003    119.666      0.000       0.340       0.352\nx7            -0.0034      0.002     -2.151      0.031      -0.006      -0.000\nx8             0.0635      0.000    129.755      0.000       0.063       0.064\nx9            -0.0105      0.003     -3.847      0.000      -0.016      -0.005\nx10           -0.2463      0.009    -28.578      0.000      -0.263      -0.229\n==============================================================================\n```\n:::\n:::\n\n\n:::\n::: {.callout-note title=\"AirBNB Reviews Interpretation\"}\n\nWe modeled the number of reviews (as a proxy for bookings) using Poisson regression. Key findings include:\n\n- **Instant bookable listings** are significantly more likely to get reviews ‚Äî suggesting ease of booking matters to users.\n- **Larger listings** (more bedrooms) and **cleanliness scores** are also strong positive predictors.\n- **Shared rooms** have much fewer bookings than entire homes, and **Private rooms** also see reduced volume.\n- **Higher prices** slightly reduce bookings, consistent with price sensitivity.\n- **\"Value\" and \"location\" scores** were surprisingly negative, possibly reflecting underlying price or geography-related confounders.\n\nOverall, the model helps identify which listing attributes are associated with higher demand in NYC‚Äôs Airbnb market.\n\n:::\n\n",
    "supporting": [
      "hw2_questions_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}